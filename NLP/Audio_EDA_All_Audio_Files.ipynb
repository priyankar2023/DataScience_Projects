{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a758d8a1",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc16e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0d90a",
   "metadata": {},
   "source": [
    "## Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb8ebbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Data/\"\n",
    "Model_path = \"/Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/\"\n",
    "audio_file = \"UrbanSound8K/audio/\"\n",
    "audio_dataset_path = path+audio_file\n",
    "metadata = \"UrbanSound8K/metadata/UrbanSound8K.csv\"\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101fd1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = pd.read_csv(path+metadata)\n",
    "\n",
    "meta_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46abc602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf018a",
   "metadata": {},
   "source": [
    "## Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc3308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, \n",
    "                                      res_type = \"kaiser_fast\")\n",
    "    mfccs_features = librosa.feature.mfcc(y = audio, \n",
    "                                          sr = sample_rate,\n",
    "                             # n_mfcc is a hyperparameter, we can try different different values such as 30, 50, 60 etc.\n",
    "                                          n_mfcc = 40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis = 0)\n",
    "    \n",
    "    return (mfccs_scaled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c6745",
   "metadata": {},
   "source": [
    "## Iterating through every audio file for feature extraction using MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49edf4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3554it [02:09, 28.83it/s]/Users/priyankar83/anaconda3/envs/tensorflow/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8324it [04:44, 41.35it/s]/Users/priyankar83/anaconda3/envs/tensorflow/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "/Users/priyankar83/anaconda3/envs/tensorflow/lib/python3.11/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [04:57, 29.35it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = []\n",
    "\n",
    "for index_num, row in tqdm(meta_data.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path), \"fold\"+str(row[\"fold\"])+\"/\", str(row[\"slice_file_name\"]))\n",
    "    final_class_labels = row[\"class\"]\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ef9c3",
   "metadata": {},
   "source": [
    "## Converting the extracted features to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ecfdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df = pd.DataFrame(data = extracted_features, columns = [\"feature\", \"class\"])\n",
    "\n",
    "extracted_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f309d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-217.35526, 70.22338, -130.38527, -53.282898,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-424.09818, 109.34077, -52.919525, 60.86475, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-458.79114, 121.38419, -46.520657, 52.00812, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-413.89984, 101.66373, -35.42945, 53.036358, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-446.60352, 113.68541, -52.402206, 60.302044,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-217.35526, 70.22338, -130.38527, -53.282898,...          dog_bark\n",
       "1  [-424.09818, 109.34077, -52.919525, 60.86475, ...  children_playing\n",
       "2  [-458.79114, 121.38419, -46.520657, 52.00812, ...  children_playing\n",
       "3  [-413.89984, 101.66373, -35.42945, 53.036358, ...  children_playing\n",
       "4  [-446.60352, 113.68541, -52.402206, 60.302044,...  children_playing"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493644ff",
   "metadata": {},
   "source": [
    "## Splitting the dataset into independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8388b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8732, 40) (8732,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(extracted_features_df[\"feature\"].values.tolist())\n",
    "y = np.array(extracted_features_df[\"class\"].values.tolist())\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb9f3b",
   "metadata": {},
   "source": [
    "## Encoding the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aecfe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(pd.get_dummies(y, dtype = int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a93845da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b620a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688d8d2",
   "metadata": {},
   "source": [
    "## Splitting the dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a7d7187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6985, 40) (1747, 40) (6985, 10) (1747, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f01a8d",
   "metadata": {},
   "source": [
    "## Finding number of classes in Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "373f6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee22ec72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48c2e1",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb3981c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae82dc",
   "metadata": {},
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5456ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#First layer\n",
    "model.add(Dense(units = 100, input_shape = (40,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Second layer\n",
    "model.add(Dense(units = 200))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Third layer\n",
    "model.add(Dense(units = 100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "#Final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbe0dd",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ad7c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e579710",
   "metadata": {},
   "source": [
    "## Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d5535bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", metrics = [\"accuracy\"], optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923a2cb",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfd56367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9562 - accuracy: 0.6883\n",
      "Epoch 1: val_loss improved from inf to 0.70684, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9545 - accuracy: 0.6885 - val_loss: 0.7068 - val_accuracy: 0.7916\n",
      "Epoch 2/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9420 - accuracy: 0.6961\n",
      "Epoch 2: val_loss improved from 0.70684 to 0.69705, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9409 - accuracy: 0.6961 - val_loss: 0.6971 - val_accuracy: 0.7962\n",
      "Epoch 3/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9258 - accuracy: 0.6921\n",
      "Epoch 3: val_loss did not improve from 0.69705\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9296 - accuracy: 0.6911 - val_loss: 0.7008 - val_accuracy: 0.7888\n",
      "Epoch 4/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9616 - accuracy: 0.6903\n",
      "Epoch 4: val_loss did not improve from 0.69705\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 0.6903 - val_loss: 0.7090 - val_accuracy: 0.7773\n",
      "Epoch 5/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9621 - accuracy: 0.6876\n",
      "Epoch 5: val_loss did not improve from 0.69705\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9591 - accuracy: 0.6883 - val_loss: 0.7087 - val_accuracy: 0.7779\n",
      "Epoch 6/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9188 - accuracy: 0.6966\n",
      "Epoch 6: val_loss did not improve from 0.69705\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9199 - accuracy: 0.6965 - val_loss: 0.7096 - val_accuracy: 0.7802\n",
      "Epoch 7/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9288 - accuracy: 0.6976\n",
      "Epoch 7: val_loss improved from 0.69705 to 0.69178, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9275 - accuracy: 0.6961 - val_loss: 0.6918 - val_accuracy: 0.7934\n",
      "Epoch 8/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9288 - accuracy: 0.6953\n",
      "Epoch 8: val_loss improved from 0.69178 to 0.67978, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9285 - accuracy: 0.6966 - val_loss: 0.6798 - val_accuracy: 0.7997\n",
      "Epoch 9/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9222 - accuracy: 0.6983\n",
      "Epoch 9: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9225 - accuracy: 0.6981 - val_loss: 0.6960 - val_accuracy: 0.7922\n",
      "Epoch 10/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9354 - accuracy: 0.6852\n",
      "Epoch 10: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9345 - accuracy: 0.6856 - val_loss: 0.7061 - val_accuracy: 0.7974\n",
      "Epoch 11/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9325 - accuracy: 0.6888\n",
      "Epoch 11: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9318 - accuracy: 0.6893 - val_loss: 0.7029 - val_accuracy: 0.7888\n",
      "Epoch 12/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.6944\n",
      "Epoch 12: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9325 - accuracy: 0.6956 - val_loss: 0.6833 - val_accuracy: 0.7985\n",
      "Epoch 13/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9260 - accuracy: 0.7021\n",
      "Epoch 13: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9248 - accuracy: 0.7021 - val_loss: 0.6947 - val_accuracy: 0.7956\n",
      "Epoch 14/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9265 - accuracy: 0.7007\n",
      "Epoch 14: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9283 - accuracy: 0.7002 - val_loss: 0.6858 - val_accuracy: 0.7974\n",
      "Epoch 15/100\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9478 - accuracy: 0.6884\n",
      "Epoch 15: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9434 - accuracy: 0.6898 - val_loss: 0.6969 - val_accuracy: 0.7979\n",
      "Epoch 16/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9427 - accuracy: 0.6909\n",
      "Epoch 16: val_loss did not improve from 0.67978\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9428 - accuracy: 0.6913 - val_loss: 0.6905 - val_accuracy: 0.7905\n",
      "Epoch 17/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9064 - accuracy: 0.7065\n",
      "Epoch 17: val_loss improved from 0.67978 to 0.67281, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.7052 - val_loss: 0.6728 - val_accuracy: 0.7962\n",
      "Epoch 18/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9390 - accuracy: 0.6922\n",
      "Epoch 18: val_loss did not improve from 0.67281\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9347 - accuracy: 0.6935 - val_loss: 0.6926 - val_accuracy: 0.8077\n",
      "Epoch 19/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9125 - accuracy: 0.7011\n",
      "Epoch 19: val_loss improved from 0.67281 to 0.66916, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9172 - accuracy: 0.7012 - val_loss: 0.6692 - val_accuracy: 0.8048\n",
      "Epoch 20/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9169 - accuracy: 0.6994\n",
      "Epoch 20: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9211 - accuracy: 0.6989 - val_loss: 0.6821 - val_accuracy: 0.8031\n",
      "Epoch 21/100\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.9160 - accuracy: 0.7027\n",
      "Epoch 21: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9152 - accuracy: 0.7028 - val_loss: 0.6711 - val_accuracy: 0.8014\n",
      "Epoch 22/100\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.8936 - accuracy: 0.7050\n",
      "Epoch 22: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.7044 - val_loss: 0.6777 - val_accuracy: 0.7962\n",
      "Epoch 23/100\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9298 - accuracy: 0.6967\n",
      "Epoch 23: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9319 - accuracy: 0.6952 - val_loss: 0.6925 - val_accuracy: 0.7905\n",
      "Epoch 24/100\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9061 - accuracy: 0.6984\n",
      "Epoch 24: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9074 - accuracy: 0.7001 - val_loss: 0.6848 - val_accuracy: 0.7882\n",
      "Epoch 25/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.9268 - accuracy: 0.6916\n",
      "Epoch 25: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9267 - accuracy: 0.6919 - val_loss: 0.6846 - val_accuracy: 0.7945\n",
      "Epoch 26/100\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9044 - accuracy: 0.6970\n",
      "Epoch 26: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9039 - accuracy: 0.6974 - val_loss: 0.6772 - val_accuracy: 0.7888\n",
      "Epoch 27/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9022 - accuracy: 0.7028\n",
      "Epoch 27: val_loss did not improve from 0.66916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9026 - accuracy: 0.7028 - val_loss: 0.6831 - val_accuracy: 0.8002\n",
      "Epoch 28/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9211 - accuracy: 0.7020\n",
      "Epoch 28: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9220 - accuracy: 0.7015 - val_loss: 0.6696 - val_accuracy: 0.8031\n",
      "Epoch 29/100\n",
      "168/219 [======================>.......] - ETA: 0s - loss: 0.9145 - accuracy: 0.6940\n",
      "Epoch 29: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9298 - accuracy: 0.6911 - val_loss: 0.6805 - val_accuracy: 0.8002\n",
      "Epoch 30/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.9109 - accuracy: 0.6875\n",
      "Epoch 30: val_loss did not improve from 0.66916\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9127 - accuracy: 0.6932 - val_loss: 0.6795 - val_accuracy: 0.8037\n",
      "Epoch 31/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.9377 - accuracy: 0.6982\n",
      "Epoch 31: val_loss improved from 0.66916 to 0.66803, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9182 - accuracy: 0.7042 - val_loss: 0.6680 - val_accuracy: 0.7991\n",
      "Epoch 32/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8953 - accuracy: 0.7064\n",
      "Epoch 32: val_loss did not improve from 0.66803\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8956 - accuracy: 0.7061 - val_loss: 0.6834 - val_accuracy: 0.8008\n",
      "Epoch 33/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.8974 - accuracy: 0.7025\n",
      "Epoch 33: val_loss improved from 0.66803 to 0.65885, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9099 - accuracy: 0.7002 - val_loss: 0.6588 - val_accuracy: 0.8008\n",
      "Epoch 34/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9034 - accuracy: 0.7014\n",
      "Epoch 34: val_loss improved from 0.65885 to 0.65354, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9034 - accuracy: 0.7014 - val_loss: 0.6535 - val_accuracy: 0.7974\n",
      "Epoch 35/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9074 - accuracy: 0.7030\n",
      "Epoch 35: val_loss did not improve from 0.65354\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9051 - accuracy: 0.7034 - val_loss: 0.6617 - val_accuracy: 0.8019\n",
      "Epoch 36/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.9019 - accuracy: 0.7029\n",
      "Epoch 36: val_loss did not improve from 0.65354\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.7047 - val_loss: 0.6621 - val_accuracy: 0.8122\n",
      "Epoch 37/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8990 - accuracy: 0.7047\n",
      "Epoch 37: val_loss improved from 0.65354 to 0.63712, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8990 - accuracy: 0.7047 - val_loss: 0.6371 - val_accuracy: 0.8134\n",
      "Epoch 38/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9098 - accuracy: 0.7018\n",
      "Epoch 38: val_loss did not improve from 0.63712\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 0.7019 - val_loss: 0.6588 - val_accuracy: 0.8025\n",
      "Epoch 39/100\n",
      "164/219 [=====================>........] - ETA: 0s - loss: 0.9078 - accuracy: 0.7024\n",
      "Epoch 39: val_loss did not improve from 0.63712\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8975 - accuracy: 0.7018 - val_loss: 0.6708 - val_accuracy: 0.8019\n",
      "Epoch 40/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.6962\n",
      "Epoch 40: val_loss did not improve from 0.63712\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9050 - accuracy: 0.6962 - val_loss: 0.6800 - val_accuracy: 0.8031\n",
      "Epoch 41/100\n",
      "164/219 [=====================>........] - ETA: 0s - loss: 0.8890 - accuracy: 0.7006\n",
      "Epoch 41: val_loss did not improve from 0.63712\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8871 - accuracy: 0.7044 - val_loss: 0.6498 - val_accuracy: 0.7991\n",
      "Epoch 42/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8905 - accuracy: 0.7059\n",
      "Epoch 42: val_loss did not improve from 0.63712\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.7059 - val_loss: 0.6670 - val_accuracy: 0.8025\n",
      "Epoch 43/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8997 - accuracy: 0.7044\n",
      "Epoch 43: val_loss did not improve from 0.63712\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8997 - accuracy: 0.7044 - val_loss: 0.6523 - val_accuracy: 0.8008\n",
      "Epoch 44/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8821 - accuracy: 0.7039\n",
      "Epoch 44: val_loss improved from 0.63712 to 0.63551, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8821 - accuracy: 0.7039 - val_loss: 0.6355 - val_accuracy: 0.8088\n",
      "Epoch 45/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8856 - accuracy: 0.7017\n",
      "Epoch 45: val_loss did not improve from 0.63551\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8835 - accuracy: 0.7025 - val_loss: 0.6527 - val_accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8872 - accuracy: 0.7056\n",
      "Epoch 46: val_loss improved from 0.63551 to 0.63245, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.7054 - val_loss: 0.6325 - val_accuracy: 0.8088\n",
      "Epoch 47/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8936 - accuracy: 0.7056\n",
      "Epoch 47: val_loss did not improve from 0.63245\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8941 - accuracy: 0.7061 - val_loss: 0.6362 - val_accuracy: 0.8128\n",
      "Epoch 48/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8655 - accuracy: 0.7195\n",
      "Epoch 48: val_loss did not improve from 0.63245\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8655 - accuracy: 0.7195 - val_loss: 0.6416 - val_accuracy: 0.7974\n",
      "Epoch 49/100\n",
      "164/219 [=====================>........] - ETA: 0s - loss: 0.8886 - accuracy: 0.7060\n",
      "Epoch 49: val_loss did not improve from 0.63245\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8819 - accuracy: 0.7104 - val_loss: 0.6486 - val_accuracy: 0.7985\n",
      "Epoch 50/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.9140 - accuracy: 0.7051\n",
      "Epoch 50: val_loss did not improve from 0.63245\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.7072 - val_loss: 0.6371 - val_accuracy: 0.8088\n",
      "Epoch 51/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8860 - accuracy: 0.7089\n",
      "Epoch 51: val_loss did not improve from 0.63245\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.7089 - val_loss: 0.6688 - val_accuracy: 0.7979\n",
      "Epoch 52/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8929 - accuracy: 0.7097\n",
      "Epoch 52: val_loss improved from 0.63245 to 0.63094, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8929 - accuracy: 0.7097 - val_loss: 0.6309 - val_accuracy: 0.8122\n",
      "Epoch 53/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8648 - accuracy: 0.7154\n",
      "Epoch 53: val_loss did not improve from 0.63094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8626 - accuracy: 0.7164 - val_loss: 0.6362 - val_accuracy: 0.8042\n",
      "Epoch 54/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.8593 - accuracy: 0.7155\n",
      "Epoch 54: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8706 - accuracy: 0.7144 - val_loss: 0.6611 - val_accuracy: 0.7985\n",
      "Epoch 55/100\n",
      "167/219 [=====================>........] - ETA: 0s - loss: 0.8519 - accuracy: 0.7176\n",
      "Epoch 55: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8679 - accuracy: 0.7148 - val_loss: 0.6345 - val_accuracy: 0.8174\n",
      "Epoch 56/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8715 - accuracy: 0.7135\n",
      "Epoch 56: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8774 - accuracy: 0.7114 - val_loss: 0.6417 - val_accuracy: 0.8105\n",
      "Epoch 57/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9179 - accuracy: 0.6977\n",
      "Epoch 57: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9184 - accuracy: 0.6975 - val_loss: 0.6335 - val_accuracy: 0.8065\n",
      "Epoch 58/100\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8860 - accuracy: 0.7121\n",
      "Epoch 58: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8860 - accuracy: 0.7118 - val_loss: 0.6422 - val_accuracy: 0.8077\n",
      "Epoch 59/100\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8793 - accuracy: 0.7059\n",
      "Epoch 59: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8827 - accuracy: 0.7037 - val_loss: 0.6379 - val_accuracy: 0.7951\n",
      "Epoch 60/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8612 - accuracy: 0.7135\n",
      "Epoch 60: val_loss did not improve from 0.63094\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8612 - accuracy: 0.7135 - val_loss: 0.6342 - val_accuracy: 0.8082\n",
      "Epoch 61/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9109 - accuracy: 0.6985\n",
      "Epoch 61: val_loss improved from 0.63094 to 0.62490, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.9109 - accuracy: 0.6985 - val_loss: 0.6249 - val_accuracy: 0.8088\n",
      "Epoch 62/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8701 - accuracy: 0.7121\n",
      "Epoch 62: val_loss did not improve from 0.62490\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8732 - accuracy: 0.7110 - val_loss: 0.6288 - val_accuracy: 0.8157\n",
      "Epoch 63/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8675 - accuracy: 0.7069\n",
      "Epoch 63: val_loss did not improve from 0.62490\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8675 - accuracy: 0.7069 - val_loss: 0.6395 - val_accuracy: 0.8002\n",
      "Epoch 64/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8689 - accuracy: 0.7204\n",
      "Epoch 64: val_loss did not improve from 0.62490\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8697 - accuracy: 0.7217 - val_loss: 0.6403 - val_accuracy: 0.8065\n",
      "Epoch 65/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8713 - accuracy: 0.7097\n",
      "Epoch 65: val_loss improved from 0.62490 to 0.61889, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8713 - accuracy: 0.7097 - val_loss: 0.6189 - val_accuracy: 0.8128\n",
      "Epoch 66/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8621 - accuracy: 0.7114\n",
      "Epoch 66: val_loss improved from 0.61889 to 0.61840, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8619 - accuracy: 0.7114 - val_loss: 0.6184 - val_accuracy: 0.8174\n",
      "Epoch 67/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8491 - accuracy: 0.7218\n",
      "Epoch 67: val_loss improved from 0.61840 to 0.61557, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8508 - accuracy: 0.7208 - val_loss: 0.6156 - val_accuracy: 0.8134\n",
      "Epoch 68/100\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.8640 - accuracy: 0.7145\n",
      "Epoch 68: val_loss did not improve from 0.61557\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8615 - accuracy: 0.7152 - val_loss: 0.6482 - val_accuracy: 0.8019\n",
      "Epoch 69/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8762 - accuracy: 0.7092\n",
      "Epoch 69: val_loss did not improve from 0.61557\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8771 - accuracy: 0.7091 - val_loss: 0.6231 - val_accuracy: 0.8100\n",
      "Epoch 70/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8861 - accuracy: 0.7046\n",
      "Epoch 70: val_loss improved from 0.61557 to 0.61147, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8860 - accuracy: 0.7047 - val_loss: 0.6115 - val_accuracy: 0.8088\n",
      "Epoch 71/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8676 - accuracy: 0.7156\n",
      "Epoch 71: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8689 - accuracy: 0.7148 - val_loss: 0.6412 - val_accuracy: 0.8019\n",
      "Epoch 72/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8891 - accuracy: 0.7064\n",
      "Epoch 72: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8891 - accuracy: 0.7064 - val_loss: 0.6326 - val_accuracy: 0.7997\n",
      "Epoch 73/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8562 - accuracy: 0.7147\n",
      "Epoch 73: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8559 - accuracy: 0.7150 - val_loss: 0.6167 - val_accuracy: 0.8031\n",
      "Epoch 74/100\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.8613 - accuracy: 0.7160\n",
      "Epoch 74: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8624 - accuracy: 0.7157 - val_loss: 0.6215 - val_accuracy: 0.8025\n",
      "Epoch 75/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8807 - accuracy: 0.7122\n",
      "Epoch 75: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8805 - accuracy: 0.7124 - val_loss: 0.6286 - val_accuracy: 0.8117\n",
      "Epoch 76/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8721 - accuracy: 0.7070\n",
      "Epoch 76: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8718 - accuracy: 0.7071 - val_loss: 0.6227 - val_accuracy: 0.8105\n",
      "Epoch 77/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8727 - accuracy: 0.7141\n",
      "Epoch 77: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8727 - accuracy: 0.7141 - val_loss: 0.6224 - val_accuracy: 0.8128\n",
      "Epoch 78/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.8500 - accuracy: 0.7227\n",
      "Epoch 78: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8547 - accuracy: 0.7183 - val_loss: 0.6411 - val_accuracy: 0.8031\n",
      "Epoch 79/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8776 - accuracy: 0.7171\n",
      "Epoch 79: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8724 - accuracy: 0.7161 - val_loss: 0.6159 - val_accuracy: 0.8163\n",
      "Epoch 80/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8739 - accuracy: 0.7144\n",
      "Epoch 80: val_loss did not improve from 0.61147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8663 - accuracy: 0.7174 - val_loss: 0.6436 - val_accuracy: 0.8088\n",
      "Epoch 81/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8395 - accuracy: 0.7213\n",
      "Epoch 81: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8392 - accuracy: 0.7211 - val_loss: 0.6526 - val_accuracy: 0.8031\n",
      "Epoch 82/100\n",
      "167/219 [=====================>........] - ETA: 0s - loss: 0.8456 - accuracy: 0.7208\n",
      "Epoch 82: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8593 - accuracy: 0.7178 - val_loss: 0.6306 - val_accuracy: 0.8019\n",
      "Epoch 83/100\n",
      "167/219 [=====================>........] - ETA: 0s - loss: 0.8623 - accuracy: 0.7169\n",
      "Epoch 83: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8691 - accuracy: 0.7137 - val_loss: 0.6197 - val_accuracy: 0.8140\n",
      "Epoch 84/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8648 - accuracy: 0.7163\n",
      "Epoch 84: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8626 - accuracy: 0.7160 - val_loss: 0.6341 - val_accuracy: 0.8117\n",
      "Epoch 85/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8577 - accuracy: 0.7178\n",
      "Epoch 85: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8604 - accuracy: 0.7150 - val_loss: 0.6513 - val_accuracy: 0.8014\n",
      "Epoch 86/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8806 - accuracy: 0.7097\n",
      "Epoch 86: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8833 - accuracy: 0.7092 - val_loss: 0.6507 - val_accuracy: 0.8082\n",
      "Epoch 87/100\n",
      "166/219 [=====================>........] - ETA: 0s - loss: 0.8509 - accuracy: 0.7186\n",
      "Epoch 87: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8518 - accuracy: 0.7170 - val_loss: 0.6288 - val_accuracy: 0.8042\n",
      "Epoch 88/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.8481 - accuracy: 0.7205\n",
      "Epoch 88: val_loss did not improve from 0.61147\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8480 - accuracy: 0.7217 - val_loss: 0.6196 - val_accuracy: 0.8077\n",
      "Epoch 89/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.8575 - accuracy: 0.7178\n",
      "Epoch 89: val_loss improved from 0.61147 to 0.59857, saving model to /Users/priyankar83/Documents/Learning/Data_Science_Learning/Deep_Learning/Audio_Classification/Model/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8488 - accuracy: 0.7207 - val_loss: 0.5986 - val_accuracy: 0.8122\n",
      "Epoch 90/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8522 - accuracy: 0.7157\n",
      "Epoch 90: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8522 - accuracy: 0.7157 - val_loss: 0.6117 - val_accuracy: 0.8134\n",
      "Epoch 91/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8392 - accuracy: 0.7192\n",
      "Epoch 91: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8390 - accuracy: 0.7191 - val_loss: 0.6250 - val_accuracy: 0.8031\n",
      "Epoch 92/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8503 - accuracy: 0.7203\n",
      "Epoch 92: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8500 - accuracy: 0.7204 - val_loss: 0.6192 - val_accuracy: 0.8082\n",
      "Epoch 93/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8723 - accuracy: 0.7146\n",
      "Epoch 93: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8719 - accuracy: 0.7148 - val_loss: 0.6209 - val_accuracy: 0.8031\n",
      "Epoch 94/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8574 - accuracy: 0.7190\n",
      "Epoch 94: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8574 - accuracy: 0.7188 - val_loss: 0.6469 - val_accuracy: 0.7974\n",
      "Epoch 95/100\n",
      "165/219 [=====================>........] - ETA: 0s - loss: 0.8938 - accuracy: 0.7013\n",
      "Epoch 95: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8885 - accuracy: 0.7049 - val_loss: 0.6238 - val_accuracy: 0.8128\n",
      "Epoch 96/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8459 - accuracy: 0.7195\n",
      "Epoch 96: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8457 - accuracy: 0.7197 - val_loss: 0.6535 - val_accuracy: 0.7974\n",
      "Epoch 97/100\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8434 - accuracy: 0.7175\n",
      "Epoch 97: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8434 - accuracy: 0.7175 - val_loss: 0.6163 - val_accuracy: 0.8128\n",
      "Epoch 98/100\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8519 - accuracy: 0.7222\n",
      "Epoch 98: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8520 - accuracy: 0.7225 - val_loss: 0.6283 - val_accuracy: 0.8122\n",
      "Epoch 99/100\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.8591 - accuracy: 0.7158\n",
      "Epoch 99: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8562 - accuracy: 0.7171 - val_loss: 0.6242 - val_accuracy: 0.8071\n",
      "Epoch 100/100\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8456 - accuracy: 0.7205\n",
      "Epoch 100: val_loss did not improve from 0.59857\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 0.8453 - accuracy: 0.7207 - val_loss: 0.6151 - val_accuracy: 0.8094\n",
      "Training completed in time:  0:00:23.781072\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = Model_path+\"audio_classification.hdf5\", \n",
    "                               verbose =1, \n",
    "                               save_best_only = True)\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size = num_batch_size, \n",
    "          epochs = num_epochs, \n",
    "          validation_data = (X_test, y_test),\n",
    "          callbacks = [checkpointer],\n",
    "          verbose = 1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76564ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093875050544739\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286ef7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
